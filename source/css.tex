% Created 2021-02-12 Fri 13:21
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{tcolorbox}
\author{josiah}
\date{\today}
\title{css test}
\hypersetup{
 pdfauthor={josiah},
 pdftitle={css test},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.1 (Org mode 9.3)}, 
 pdflang={English}}
\begin{document}

\maketitle
\section*{this is the first header}
\label{sec:org4b9debc}
this is a normal paragraph, and it contains a line that wraps naturally due to length. its pretty cool. below me is a list:
\begin{enumerate}[noitemsep]
\item item 1
\item item 2
\item item 3
\begin{itemize}
\item unordered 1
\item 2
\item 3
\end{itemize}
\end{enumerate}

\section*{below is a picture embed with caption}
\label{sec:org5388653}
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{/home/josiah/Pictures/pagedout_slack_example.png}
\caption{\label{fig:orgb453e3c}Make sure you use the "Bot User OAuth Access Token" in a "Classic Slack App"; anything else won't work.}
\end{figure}

\section*{here is a python embd}
\label{sec:orgd1e1678}

\begin{verbatim}
import slack

def reactable_string(text):
    reactable_array = []
    t = text.lower()
    if 'cyber' in t:
	reactable_array.append('robot')
    if 'flavor town' in t:
	reactable_array.append('flavortown')
    return reactable_array

def rtm(emoji, payload, id, ts):
    payload['web_client'].reactions_add(
	channel=id,
	name=emoji,
	timestamp=ts
    )

    return None


@slack.RTMClient.run_on(event='message')
def handle_messages(**payload):
    data = payload['data']
    id = data['channel']
    ts = data['ts']

    if reactable_string(data['text']):
	needed = reactable_string(data['text'])

	if 'robot' in reactions_needed:
	    rtm("robot_face", payload, id, ts)
	if 'flavortown' in reactions_needed:
	    rtm("dark_sunglasses", payload, id, ts)
	    rtm("guyfieri", payload, id, ts)


if __name__ == '__main__':
    stoken = 'XXXXXXXXXXXXXXXX'  # Secret token!!
    rtm_client = slack.RTMClient(token=stoken)
    rtm_client.start()
\end{verbatim}

\section*{here is a listp embed}
\label{sec:org7fc1cb6}

\begin{verbatim}
(let ((proj-base (file-name-directory load-file-name)))
  (setq org-publish-project-alist
	`(("project-name"
	   :base-directory ,(concat proj-base ".")
	   :recursive t
	   :publishing-directory ,(concat proj-base  "../export")
	   :publishing-function org-html-publish-to-html))))
\end{verbatim}
\section*{see links styling}
\label{sec:org5bf6e67}
\url{https://me.jowj.net} looks like this

\section*{here are some tooltips}
\label{sec:org140d24f}
\begin{parallel}
\begingroup\color{orange}Are you excited to learn some Lisp?\endgroup\, \begingroup\color{blue}Yes!\endgroup\,

Pop-quiz: How does \hyperref[org-special-block-extras-glossary-apply]{apply}\label{org-special-block-extras-glossary-declaration-site-apply} work?
\end{parallel}

\begin{details}

Syntactically, \texttt{(apply f '(x0 ... xN)) = (f x0 ... xN)}.

{\color{black} \fbox{\bf [Musa:} Ain't that cool?  \fbox{\bf ]}}

\begin{spoiler}
That is, \begingroup\color{magenta}we can ((apply)) a function to a list of arguments!\endgroup\,
\end{spoiler}
\end{details}

\begin{box}
 Note that \texttt{C-x C-e} evaluates a Lisp form!
\end{box}
\!\!${}^{\textnormal{{\thefootnote}}}$
               \newsavebox{\OrgSpecialBlockExtrasMarginBox}
               \begin{lrbox}{\OrgSpecialBlockExtrasMarginBox}
               \begin{minipage}{\paperwidth - \textwidth - \oddsidemargin - 1in - 3ex}
               \raggedright \iffalse Otherwise default alignment is fully justified. \fi
               \footnotesize
               \setminted{fontsize=\footnotesize, breaklines} \iffalse HACK! \fi
               \color{gray!80}
               {\color{black}${}^{\textnormal{{\thefootnote}}}$}
\normalfont
 hello
               \end{minipage}
               \end{lrbox}
               \marginpar{\usebox{\OrgSpecialBlockExtrasMarginBox}\stepcounter{footnote}}
               \hspace{-1.9ex}
               \global\let\OrgSpecialBlockExtrasMarginBox\relax
\emph{Allah \!\!${}^{\textnormal{{\thefootnote}}}$
               \newsavebox{\OrgSpecialBlockExtrasMarginBox}
               \begin{lrbox}{\OrgSpecialBlockExtrasMarginBox}
               \begin{minipage}{\paperwidth - \textwidth - \oddsidemargin - 1in - 3ex}
               \raggedright \iffalse Otherwise default alignment is fully justified. \fi
               \footnotesize
               \setminted{fontsize=\footnotesize, breaklines} \iffalse HACK! \fi
               \color{gray!80}
               {\color{black}${}^{\textnormal{{\thefootnote}}}$}
\normalfont
 The God of Abraham; known as Elohim in the Bible
               \end{minipage}
               \end{lrbox}
               \marginpar{\usebox{\OrgSpecialBlockExtrasMarginBox}\stepcounter{footnote}}
               \hspace{-1.9ex}
               \global\let\OrgSpecialBlockExtrasMarginBox\relax does
not burden a soul beyond what it can bear.} --- Quran 2:286

In the LaTeX output, we have a glossary.

\vspace{1em}\phantomsection\textbf{apply}\quad\label{org-special-block-extras-glossary-apply}Call FUNCTION with our remaining args, using our last arg as list of args. \newline{\color{white}.}Then return the value FUNCTION returns. \newline{\color{white}.}Thus, (apply '+ 1 2 '(3 4)) returns 10. \newline{\color{white}.} \newline{\color{white}.}(fn FUNCTION \&rest ARGUMENTS) See page \pageref{org-special-block-extras-glossary-declaration-site-apply}

\vspace{1em}\phantomsection\textbf{Difunctional}\quad\label{org-special-block-extras-glossary-Difunctional}This property generalises injectivity, univalence, and equivalence... \newline{\color{white}.} \newline{\color{white}.}Recall, \newline{\color{white}.}- Univalent: Every source value /x/ is associated *at most one* target value /y/. \newline{\color{white}.} \quad  \quad + I.e., if /x/ goes to /y/ and /y′/ then /y = y′/. \newline{\color{white}.} \quad  \quad + I.e., $∀ x, y′, y •\quad \quad x 〔R〕 y \quad 〔R˘〕 x 〔R〕 y′ \;⇒\; y 〔Id〕 y′$ \newline{\color{white}.}- Injective: Every source value /y/ is associated *at most* one source value /x/. \newline{\color{white}.} \quad  \quad + I.e., if /y/ comes from /x/ and /x′/ then /x = x′/. \newline{\color{white}.} \quad  \quad + I.e., $∀ x, x′, y •\quad \quad x 〔R〕 y \quad 〔R˘〕 x′ 〔R〕 y \;⇒\; x 〔Id〕 x′$ \newline{\color{white}.}- Equivalence: Any given equivalence classes are either identical or disjoint. \newline{\color{white}.} \quad  \quad  \quad # + I.e., $∀ x, y •\quad \quad x 〔R〕 y \quad 〔R˘〕 x 〔R〕 y′ \;⇒\; x 〔R〕 y′$ \newline{\color{white}.} \quad  \quad + Moreover, it is a /homogenous/ relation. \newline{\color{white}.} \newline{\color{white}.} Now, a /possibly heterogenous/ relation /R/ is /difunctional/ exactly when \newline{\color{white}.} $∀ x, x′, y′, y •\quad \quad x 〔R〕 y \quad 〔R˘〕 x′ 〔R〕 y′ \;⇒\; x 〔R〕 y′$. \newline{\color{white}.} That is, $R ⨾ R ˘ ⨾ R ⊆ R$; in-fact we have equality $R ⨾ R ˘ ⨾ R = R$. \newline{\color{white}.} Using Schröder, this amounts to $R ⨾ ∼R ˘ ⨾ R \;⊆\; ∼R$. \newline{\color{white}.} \newline{\color{white}.} Clearly, converse preserves difunctionality. \newline{\color{white}.} \newline{\color{white}.} For difunctional /R/, \newline{\color{white}.} 1. /R ⨾ (Q ∩ R˘ ⨾ S) = R ⨾ Q ∩ R ⨾ R˘ ⨾ S/ \newline{\color{white}.} 2. $R ⨾ ∼(R ˘ ⨾ Q) \;=\; R ⨾ ⊤ ∩ ∼(R ⨾ R˘ Q)$ \newline{\color{white}.} 3. $∼(R ⨾ R ˘ ⨾ Q) \;=\; R ⨾ ∼(R˘ ⨾ Q) ∪ ∼(R ⨾ ⊤)$ \newline{\color{white}.} 4. $R ⨾ ∼(R ˘ ⨾ Q) \;=\; ∼(R ⨾ R˘ Q)$, if /R/ is also total. \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}The equivalence target-saturation of a univalent relation is difunctional; i.e., \newline{\color{white}.}if /R/ is univalent and Ξ is an equivalence, then $R ⨾ Ξ$ is difunctional. See page \pageref{org-special-block-extras-glossary-declaration-site-Difunctional}

\vspace{1em}\phantomsection\textbf{Iso}\quad\label{org-special-block-extras-glossary-Iso}An *iso* is a bijective mapping, also known as a *permutation.* \newline{\color{white}.} \newline{\color{white}.}An isomorphism is a non-lossy protocol associating inputs to outputs. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, an iso is a /bunch of circles/: Any number of cycles, such that \newline{\color{white}.}every node lies on exactly one. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}If relation $R$ is finite, then \newline{\color{white}.}$R ⨾ R ˘ = Id \quad≡\quad \quad (∃ m • Rᵐ = Id ∧ Rᵐ⁻¹ = R ˘)$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. See page \pageref{org-special-block-extras-glossary-declaration-site-Iso}

\vspace{1em}\phantomsection\textbf{Bijective}\quad\label{org-special-block-extras-glossary-Bijective}*Bijective:* /Every source value y is associated *exactly one* source value x./ \newline{\color{white}.} \newline{\color{white}.} \quad  $R$ is bijective \newline{\color{white}.}≡ \quad $R$ is injective and surjective \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, bijectivity means: /Every node has exactly one outgoing edge/. See page \pageref{org-special-block-extras-glossary-declaration-site-Bijective}

\vspace{1em}\phantomsection\textbf{Injective}\quad\label{org-special-block-extras-glossary-Injective}*Injective:* /Every source value y is associated *at most* one source value x./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, injective means: /Every node has at most one incoming edge./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \quad  $R$ is injective \newline{\color{white}.}≡ \quad $R˘$ is univalent \newline{\color{white}.}≡ \quad $R \quad ⨾ R ˘ ⊆ Id$ \newline{\color{white}.}≡ \quad $∼ Id ⨾ R \;⊆\; ∼ R$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. See page \pageref{org-special-block-extras-glossary-declaration-site-Injective}

\vspace{1em}\phantomsection\textbf{Surjective}\quad\label{org-special-block-extras-glossary-Surjective}*Surjective:* /Every source value y is associated *at least* one source value x./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, surjectivity means: /Every node has at least one incoming edge./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \quad  $R$ is surjective \newline{\color{white}.}≡ \quad $R˘$ is total \newline{\color{white}.}≡ \quad $⊤ ⨾ R = ⊤$ \newline{\color{white}.}≡ \quad $Id ⊆ R ˘ ⨾ R$ \newline{\color{white}.}≡ \quad $∼ R \;⊆\; ∼ Id ⨾ R$ \newline{\color{white}.}≡ \quad /∀ S • R ⨾ S = ⊥ ≡ S = ⊥/ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. See page \pageref{org-special-block-extras-glossary-declaration-site-Surjective}

\vspace{1em}\phantomsection\textbf{Map}\quad\label{org-special-block-extras-glossary-Map}*Map (totally defined function):* /Every source value x is associated *exactly one* \newline{\color{white}.}target value y./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple relation, being a mapping means: /Every node has exactly one outgoing edge./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \quad  $F$ is a map \newline{\color{white}.}≡ \quad $F$ is total and univalent \newline{\color{white}.}≡ \quad $F ⨾ ∼ Id \;=\; ∼ F$ \newline{\color{white}.}≡ \quad $∀ S • F ⨾ ∼ S \;=\; ∼ (F ⨾ S)$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}The final rule says /the preimage of the complement is the complement of the \newline{\color{white}.}preimage/; or, using conventional direct image notation, $f⁻¹(∼ A) \;=\; ∼ \newline{\color{white}.}f⁻¹(A)$. \newline{\color{white}.} \newline{\color{white}.}In conventional direct image notation, this amount to a Galois connection: $A ⊆ \newline{\color{white}.}f⁻¹(B) \quad≡\quad f(A) ⊆ B$. \newline{\color{white}.} \newline{\color{white}.}A mapping is so very close to being invertible since mappings $F$ always \newline{\color{white}.}satisfy: $F ˘ ⨾ F ⊆ Id$ and $Id ⊆ F ⨾ F˘$. \newline{\color{white}.} \newline{\color{white}.}Shunting rule:* If $F$ is a map, then $R ⊆ S ⨾ F ˘ \quad≡\quad R ⨾ F ⊆ S$. \newline{\color{white}.} \newline{\color{white}.}More generally, given an equivalence Ξ, if relation /F/ is total and Ξ-univalent \newline{\color{white}.}---i.e., /F˘ ⨾ F ⊆ Ξ/--- and if /S/ is Ξ-target-saturated ---i.e., /S ⨾ Ξ = S/--- \newline{\color{white}.}then $R ⊆ S ⨾ F ˘ \quad≡\quad R ⨾ F ⊆ S$. See page \pageref{org-special-block-extras-glossary-declaration-site-Map}

\vspace{1em}\phantomsection\textbf{Total}\quad\label{org-special-block-extras-glossary-Total}*Total:* /Every source value x is associated *at least one* target value y./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, totality means: /Every node has at least one outgoing edge/. \newline{\color{white}.} \newline{\color{white}.} \quad  $R$ is total \newline{\color{white}.}≡ \quad /∀ x • ∃ y • x 〔 R 〕 y/ \newline{\color{white}.}≡ \quad $⊤ = R ⨾ ⊤$ (“defined everywhere”) \newline{\color{white}.}≡ \quad $⊥ = ∼ (R ⨾ ⊤)$ \newline{\color{white}.}≡ \quad $Id ⊆ R ⨾ R ˘$ \newline{\color{white}.}≡ \quad $∼ R \;⊆\; R ⨾ ∼ Id$ \newline{\color{white}.}≡ \quad $∀ S • ∼ (R ⨾ S) \;⊆\; R ⨾ ∼ S$ \newline{\color{white}.}≡ \quad $∀ Q • Q ⨾ R = ⊥ ≡ Q = ⊥$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}The formula $∼ R \;⊆\; R ⨾ ∼ Id$ reads “If /x/ is not /R/-related to y, then /x/ is /R/ \newline{\color{white}.}related to some element different from /y/.” \quad It continues to hold when we replace \newline{\color{white}.}the identity by an arbitrary relation. \newline{\color{white}.} \newline{\color{white}.}The final formula says that $R$ is post-annihilated by the empty relation only. \newline{\color{white}.} \newline{\color{white}.}Note: $∼(R ⨾ ⊤) = ⊤ \;≡\; R = ⊥$, for any $R$; i.e., /the complement of a \newline{\color{white}.}relation's domain is everything precisely when the relation is empty./ See page \pageref{org-special-block-extras-glossary-declaration-site-Total}

\vspace{1em}\phantomsection\textbf{Univalent}\quad\label{org-special-block-extras-glossary-Univalent}*Univalent (partially defined function):* /Equal elements are related to equal \newline{\color{white}.}elements; i.e., an element cannot be related to two different elements./ \newline{\color{white}.} \newline{\color{white}.}/That is, every source value x is associated *at most one* target value y./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. That is relations are /simple graphs/; one refers to the directed lines \newline{\color{white}.}as /edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, univalence means: /Any arcs from the same source actually coincide./ \newline{\color{white}.}That is, /Every node has at most one outgoing edge./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \quad  $R$ is univalent \newline{\color{white}.}≡ \quad /∀ x, y, y′ \quad • x 〔 R 〕 y ∧ x 〔R〕 y′ \quad ⇒ y = y′/ \newline{\color{white}.}≡ \quad $R ˘ ⨾ R \quad ⊆ Id$ \newline{\color{white}.}≡ \quad $R ⨾ ∼ Id \;⊆\; ∼ R$ \newline{\color{white}.}≡ \quad $∀ S • R ⨾ ∼ S \;⊆\; ∼ (R ⨾ S)$ \newline{\color{white}.}≡ \quad /∀ S • R ⨾ ∼ S = R ⨾ ⊤ ∩ ∼(R ⨾ S)/ \newline{\color{white}.}≡ \quad /∀ Q, S • \quad R ⨾ (Q ∩ S) = R ⨾ Q ∩ R ⨾ S/ \quad  ---c.f., ⨾ sub-distributes over ∩ \newline{\color{white}.}≡ \quad /∀ Q, S • Q⨾R ∩ S = (Q ∩ S ⨾ R˘)⨾R/ \quad  \quad  \quad  ---c.f., the Dedekind rule \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}The formula $R ⨾ ∼ Id \;⊆ ∼ R$ reads “If /x/ is /R/-related to a value different \newline{\color{white}.}from /y/, then it is not /R/-related to /y/.” \quad It continues to hold when we replace \newline{\color{white}.}the identity by an arbitrary relation. \newline{\color{white}.} \newline{\color{white}.}The 5th row reads, /the preimage of the complement is the same as the complement \newline{\color{white}.}of the preimage intersected with the domain/. \quad In fact, for univalent $R$, we \newline{\color{white}.}also have $∼(R ⨾ S) = R ⨾ ∼ S ∪ ∼(R ⨾ ⊤)$; e.g., the people who do “not (own an \newline{\color{white}.}Audi car)” are exactly the people who “(own a non-Audi car) or do not(own any \newline{\color{white}.}car)” ---assuming a person can own at most one car. \newline{\color{white}.} \newline{\color{white}.}For a map $f$, the 6th row becomes: $f(A ∩ B) \;=\; f(A) ∩ f(B)$, using \newline{\color{white}.}conventional direct image notation; i.e., for a function, /the preimage of an \newline{\color{white}.}intersection is the intersection of preimages/. \newline{\color{white}.} \newline{\color{white}.}Likewise, for a map $f$, we have /the intersection of $B$ with a function's image \newline{\color{white}.}is the same as the image of an intersection involving the preimage of $B$/; i.e., \newline{\color{white}.}$f(A) ∩ B = f(A ∩ f^{-1}(B))$. See page \pageref{org-special-block-extras-glossary-declaration-site-Univalent}

\vspace{1em}\phantomsection\textbf{Semilinear}\quad\label{org-special-block-extras-glossary-Semilinear}/Any two different members are related/; (the associated graph can be drawn \newline{\color{white}.}similar to a line). \newline{\color{white}.} \newline{\color{white}.}( In graph terminology, semilinear is also referred to as /complete/; e.g., /“the \newline{\color{white}.}complete graph on n nodes”/ refers to $⊤ ∩ ∼Id : 1..n ↔ 1..n$. ) \newline{\color{white}.} \newline{\color{white}.} \quad  $R$ is semilinear \newline{\color{white}.}≡ \quad /∀ x, y • x ≠ y \quad ⇒ \quad x 〔R〕 y \quad ∨ \quad y 〔R〕 x/ \newline{\color{white}.}≡ \quad $∼Id ⊆ R ∪ R ˘$ \newline{\color{white}.}≡ \quad $∼ R ⊆ R ˘ ∪ Id$ \newline{\color{white}.}≡ \quad $∼ R$ is antisymmetric \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.} \newline{\color{white}.}A relation without incomparable elements is semilinear. \newline{\color{white}.} \newline{\color{white}.}A semilinear and asymmetric relation $R$ is known as a /tournament/ since it \newline{\color{white}.}models the win-loss situation of a typical sports tournament: Semilinearity and \newline{\color{white}.}asymmetry ensure teams do not play against themselves and that there is no draw \newline{\color{white}.}---i.e., there must be a winner. A tournament /R/ is characterised by /R ∪ R˘ = \newline{\color{white}.}∼Id/. See page \pageref{org-special-block-extras-glossary-declaration-site-Semilinear}

\vspace{1em}\phantomsection\textbf{Linear}\quad\label{org-special-block-extras-glossary-Linear}/Any two (possibly identical) members are related/; (the associated \newline{\color{white}.}graph can be drawn /similar/ to a line; i.e., the nodes can be arranged in a \newline{\color{white}.}sequence). \newline{\color{white}.} \newline{\color{white}.}( In graph terminology, linear is also referred to as /strongly complete/. ) \newline{\color{white}.} \newline{\color{white}.}( Sometimes a linear /order/ is called a /complete order/. ) \newline{\color{white}.} \newline{\color{white}.} \quad  $R$ is linear \newline{\color{white}.}≡ \quad /∀ x, y • x 〔R〕 y \quad ∨ \quad y 〔R〕 x/ \newline{\color{white}.}≡ \quad $⊤ ⊆ R ∪ R ˘$ \newline{\color{white}.}≡ \quad $∼ R ⊆ R ˘$ \newline{\color{white}.}≡ \quad $∼ R$ is asymmetric \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A linear /order/ corresponds to a full upper triangular matrix, /after/ suitably \newline{\color{white}.}arranging rows and columns. A linear (pre)-/order/ has no (distinct) incomparable \newline{\color{white}.}elements. \newline{\color{white}.} \newline{\color{white}.}Any linear ordering /E/, with associated strict order /C/, satisfies $C˘ = ∼E$; \newline{\color{white}.}i.e., any linear order ‘⊑’ satisfies $∀ x, y •\quad ¬ (x ⊑ y) \;≡\; y ⊏ x$. \newline{\color{white}.} \newline{\color{white}.}Likewise, for liner order, we have /transitivity E⨾C⨾E = C/ and /weakening C ⊆ E/; \newline{\color{white}.}i.e., $a ⊑ b ⊏ c ⊑ d \;⇒\; a ⊏ d \quad\; and\; \quad x ⊏ y \;⇒\; x ⊑ y$. \newline{\color{white}.} \newline{\color{white}.}Every order /E/ can be extended to a linear order /E′/; i.e., /E ⊆ E′/. \quad For the \newline{\color{white}.}finite case this is known as /topological sort/, and for the infinite case this is \newline{\color{white}.}known as the /Szpilrajn extension/. \newline{\color{white}.} \newline{\color{white}.}- For the finite case, the /idea/ is as follows: If /E/ is not linear, then there \newline{\color{white}.} \quad are two incomparable elements /x, y/ (i.e., outside /E ∪ E˘/), so we may define \newline{\color{white}.} \quad /an/ ordering /E₁ ≔ E ∪ {(x, y)}/. We iterate this process and /Eₙ/ will \newline{\color{white}.} \quad eventually become linear. \newline{\color{white}.} \newline{\color{white}.} \quad This process maintains “the order /E/, less the incomparable elements, is \newline{\color{white}.} \quad linear” invariant throughout. Since each step reduces the number of \newline{\color{white}.} \quad incomparable elements, it must terminate, and the invariant then ensures the \newline{\color{white}.} \quad resulting order is linear. (•̀ᴗ•́)و See page \pageref{org-special-block-extras-glossary-declaration-site-Linear}

\vspace{1em}\phantomsection\textbf{Equivalence}\quad\label{org-special-block-extras-glossary-Equivalence}An /equivalence/ models the notion of ‘similarity’; /Everything is similar to \newline{\color{white}.}itself, being similar is a mutual relationship, and it is transitive/. \newline{\color{white}.} \newline{\color{white}.} \quad  $R$ is an equivalence \newline{\color{white}.}≡ \quad $R$ is a symmetric preorder \newline{\color{white}.}≡ \quad $R$ is transitive and reflexive and symmetric \newline{\color{white}.}≡ \quad $R ⨾ R ⊆ R \;∧\; Id ⊆ R ⊆ R˘$ \newline{\color{white}.}≡ \quad $R ⨾ R = R = R˘ \;∧\; Id ⊆ R$ \newline{\color{white}.}≡ \quad $R ⨾ R ˘ ⊆ R \;∧\; Id ⊆ R$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}For example, “2 + 3” and “5” are clearly *not the same*”: The first is a string \newline{\color{white}.}of 3 symbols, whereas the latter is a string of a single symbol. \quad However, they \newline{\color{white}.}are *equivalent* when we evaluate them and so we want to pretend they are the \newline{\color{white}.}same, not by using equality, but by using an equivalence relation. \quad ( This \newline{\color{white}.}equivalence relation is obtained using transitive closure as $(R ⨾ R)^*$ where \newline{\color{white}.}$R$ is the evaluation, reduction relation. ) \newline{\color{white}.} \newline{\color{white}.}In general, “sharing the same feature 𝒇” is an equivalence relation. \newline{\color{white}.}That is, if $f : A → B$ is a function, then ∼ is an equivalence relation \newline{\color{white}.}defined by $a₁ ∼ \quad a₂ \quad≡\quad f(a₁) \;=\; f(a₂)$. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}Characterising Equivalences with “Indirect Equivalence”: \newline{\color{white}.}Ξ is an equivalence \quad ≡ \quad $∀ x, y • \quad x 〔Ξ〕 y \quad≡\quad (∀ z • x 〔Ξ〕 z \;≡\; y 〔Ξ〕 z)$ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}Equivalence relations coincide with partitions. See page \pageref{org-special-block-extras-glossary-declaration-site-Equivalence}

\vspace{1em}\phantomsection\textbf{Preorder}\quad\label{org-special-block-extras-glossary-Preorder}A /preorder/ models the notion of ‘inclusion’ or ‘at most’ or ‘before’ or \newline{\color{white}.}‘predecessor of’; and so requires: /Everything is included in itself and \newline{\color{white}.}inclusion is transitive./ \newline{\color{white}.} \newline{\color{white}.} \quad $R$ is a preorder \newline{\color{white}.}≡ $R$ is transitive and reflexive \newline{\color{white}.}≡ $R ⨾ R ⊆ R \;∧\; Id ⊆ R$ \newline{\color{white}.}≡ $R ⨾ R = R \;∧\; Id ⊆ R$ \newline{\color{white}.}≡ $R ╱ R = R$ \quad ---“indirect inclusion from above” \newline{\color{white}.}≡ $R ╲ R = R$ \quad ---“indirect inclusion from below” \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.} \newline{\color{white}.}If it is additionally /antisymmetric/, one says we have an *order*. \newline{\color{white}.}- The relation $R ∩ R˘$ is the greatest equivalence contained in a preorder $R$. \newline{\color{white}.} \newline{\color{white}.} \quad Indeed, it's clearly symmetric and reflexive, and transitive since ‘⨾’ \newline{\color{white}.} \quad sub-distributes over ‘∩’ and /R/ and /R˘/ are transitive. Then, for any \newline{\color{white}.} \quad equivalence /Ξ ⊆ R/, we have /Ξ = Ξ ˘ ⊆ R ˘/ and so /Ξ ⊆ R ∩ R˘/. \newline{\color{white}.} \newline{\color{white}.}Instead of reflexivity, if we have irreflexivity we get *strict order*: \newline{\color{white}.} \quad $R$ is a strict order \newline{\color{white}.}≡ $R$ is transitive and irreflexive \newline{\color{white}.}≡ $R ⨾ R ⊆ R ⊆ ∼Id$ \newline{\color{white}.}≡ $R ⨾ R ⊆ R \;∧\; R˘ ⊆ ∼ R$ \newline{\color{white}.}≡ $R ⨾ R ⊆ R \;∧\; R ∩ R˘ ⊆ ⊥$ \newline{\color{white}.}≡ $R$ is transitive and asymmetric \newline{\color{white}.} \newline{\color{white}.}( /Warning!/ A “strict order” is not an order that is somehow strict. ) \newline{\color{white}.} \newline{\color{white}.}Orders and strict orders come in pairs: Every order $R$ induces a strict order \newline{\color{white}.}$R ∩ ∼Id$; conversely, every strict order $R$ gives rise to an order $R ∪ \newline{\color{white}.}Id$. As such, it is customary to denote order relations by symbols such as ≤, \newline{\color{white}.}⊆. ≼, ⊑ and their associated strict orders by related symbols <, ⊂, ≺, ⊏, \newline{\color{white}.}respectively, with *lack the horizontal line ‘─’ below the symbol to indicate \newline{\color{white}.}irreflexivity ---i.e., the line is a suggestive reminder of equality. \newline{\color{white}.} \newline{\color{white}.}When letters are used to denote orders, one may see /E/ for an order since it is \newline{\color{white}.}reminiscent of ≤ and ⊆, and may see /C/ for a strict order since it is reminiscent \newline{\color{white}.}of < and ⊂. \newline{\color{white}.} \newline{\color{white}.}Using ‘≤’ for /an arbitrary order/ is not ideal since readers may confuse it with \newline{\color{white}.}the familiar /linear/ orders for numbers. See page \pageref{org-special-block-extras-glossary-declaration-site-Preorder}

\vspace{1em}\phantomsection\textbf{Asymmetric}\quad\label{org-special-block-extras-glossary-Asymmetric}/The relationship is mutually exclusive./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. \quad That is relations are /simple graphs/; one refers to the directed lines as \newline{\color{white}.}/edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, asymmetric means: /There's at most 1 edge (regardless of \newline{\color{white}.}direction) relating any 2 nodes/. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \quad  $R$ is asymmetric \newline{\color{white}.}≡ \quad /∀ x, y • x 〔R〕 y \quad ⇒ \quad ¬ y 〔R〕 x/ \newline{\color{white}.}≡ \quad $R ∩ R ˘ ⊆ ⊥$ \newline{\color{white}.}≡ \quad $R ˘ ⊆ ∼ R$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.} \newline{\color{white}.}Asymmetrics are irreflexive ---just pick /x = y/ in the above ∀-formulation ;-) \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Interestingly, every homogeneous relation /R/ may be /partitioned/ into an \newline{\color{white}.}asymmetric part $A = R ∩ ∼R˘$ and a symmetric part $S = R ∩ R˘$ \newline{\color{white}.}---i.e., $R = A ∪ S$ and $A ∩ S = ⊥$ where ⊥ is the empty relation. See page \pageref{org-special-block-extras-glossary-declaration-site-Asymmetric}

\vspace{1em}\phantomsection\textbf{Antisymmetric}\quad\label{org-special-block-extras-glossary-Antisymmetric}/Different elements cannot be mutually related; i.e., \newline{\color{white}.}Mutually related items are necessarily indistinguishable./ \newline{\color{white}.} \newline{\color{white}.}Such relations allow us to prove equality between two elements; \newline{\color{white}.}we have only to show that the relationship holds in both directions. \newline{\color{white}.} \quad * E.g, one often shows two sets are equal by using the antisymmetry of ‘⊆’. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. \quad That is relations are /simple graphs/; one refers to the directed lines as \newline{\color{white}.}/edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, antisymmetry means /Mutually related nodes are necessarily self-loops/. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \quad  $R$ is antisymmetric \newline{\color{white}.}≡ \quad /∀ x, y • x 〔R〕 y \quad ∧ \quad y 〔 R〕 x ⇒ x = y/ \newline{\color{white}.}≡ \quad /∀ x, y • \quad x ≠ y \quad ⇒ \quad ¬ (x 〔R〕 y \quad ∧ \quad y 〔 R〕 x)/ \newline{\color{white}.}≡ \quad /∀ x, y • \quad x ≠ y \quad ⇒ \quad x 〔R̸〕 y \quad ∨ \quad y 〔 R̸〕 x/ \newline{\color{white}.}≡ \quad $R ∩ R ˘ ⊆ Id$ \newline{\color{white}.}≡ \quad $R ˘ ⊆ ∼ R ∪ Id$ \newline{\color{white}.}≡ \quad /R ╳ R = Id/ \quad ---‘╳’ is symmetric quotient \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.} \newline{\color{white}.}( As a simple graph, an antisymmetric relation has /at most/ one arrow between \newline{\color{white}.}any two different nodes. ) See page \pageref{org-special-block-extras-glossary-declaration-site-Antisymmetric}

\vspace{1em}\phantomsection\textbf{Symmetric}\quad\label{org-special-block-extras-glossary-Symmetric}/The relationship is mutual; if one thing is related to the other, then the other \newline{\color{white}.}is also related to the first./ \newline{\color{white}.} \newline{\color{white}.} \quad  $R$ is symmetric \newline{\color{white}.}≡ \quad If /x/ is related to /y/, then /y/ is also related to /x/. \newline{\color{white}.}≡ \quad /∀ x, y • x 〔R〕 y ⇒ y 〔 R〕 x/ \newline{\color{white}.}≡ \quad $R ˘ ⊆ R$ \newline{\color{white}.}≡ \quad $R ∩ R˘ ⊆ R$ \newline{\color{white}.}≡ \quad $R ˘ = R$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. \quad That is relations are /simple graphs/; one refers to the directed lines as \newline{\color{white}.}/edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, symmetry means the graphs is /undirected/. \newline{\color{white}.} \newline{\color{white}.}That is, as graphs, symmetric relations contains either exactly two arrows ---in \newline{\color{white}.}opposite directions--- between any two elements or none at all. \quad As such, for \newline{\color{white}.}clarity, one prefers “squeezing any two arrows in opposite directions” into one \newline{\color{white}.}‘undirected’ line and so obtains *undirected graphs*. \newline{\color{white}.}- Undirected edges represent pairs of arrows pointing in opposite directions. \newline{\color{white}.} \newline{\color{white}.} \quad Coreflexives are symmetric: $R ⊆ Id ⇒ R ˘ = R$. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Interestingly, every homogeneous relation /R/ may be /partitioned/ into an \newline{\color{white}.}asymmetric part $A = R ∩ ∼R˘$ and a symmetric part $S = R ∩ R˘$ \newline{\color{white}.}---i.e., $R = A ∪ S$ and $A ∩ S = ⊥$ where ⊥ is the empty relation. See page \pageref{org-special-block-extras-glossary-declaration-site-Symmetric}

\vspace{1em}\phantomsection\textbf{Transitive}\quad\label{org-special-block-extras-glossary-Transitive}A relation _⊑_ is /transitive/ when it satisfies /a ⊑ b \quad ∧ \quad b ⊑ c \quad ⇒ \quad a ⊑ c/; \newline{\color{white}.}i.e., /a ⊑ b ⊑ c \quad ⇒ a ⊑ c/ ---that is, “we can chain ⊑” so that from a proof of /a \newline{\color{white}.}⊑ b ⊑ c/ we can get from the first to the final part and so have a proof of \newline{\color{white}.}/a ⊑ c/. \newline{\color{white}.} \newline{\color{white}.}Loosely put, whenever /a/ and /c/ have a common relative then they are themselves \newline{\color{white}.}related. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. \quad That is relations are /simple graphs/; one refers to the directed lines as \newline{\color{white}.}/edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, transitivity means /paths can always be shortened (but \newline{\color{white}.}nonempty)./ \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}By the shunting rule, transitivity can be read as a *‘monotonicity’* property for \newline{\color{white}.}the operation that turns a value /x/ into the proposition /a ⊑ x/; this maps ordered \newline{\color{white}.}relationships /b ⊑ c/ to ordered propositions /a ⊑ b ⇒ a ⊑ c/. \newline{\color{white}.} \newline{\color{white}.}Likewise, transitivity can be read as an ‘*antitonicity*’ property for the \newline{\color{white}.}operation mapping a value /x/ to the proposition /x ⊑ c/; this maps ordered \newline{\color{white}.}relationships /a ⊑ b/ to ordered propositions /b ⊑ c ⇒ a ⊑ c/. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.} \quad  Relation /R/ is transitive \newline{\color{white}.}≡ \quad /Things related to things that are related, are themselves related./ \newline{\color{white}.}≡ \quad Whenever /x/ is related to /y/ and /y/ is related to /z/, then also /x/ will \newline{\color{white}.} \quad  be related to /z/ \newline{\color{white}.}≡ \quad /∀ x, y, z • \quad x 〔 R 〕 y 〔R 〕 z \quad ⇒ \quad x 〔R〕 z/ \newline{\color{white}.}≡ \quad $R ⨾ R ⊆ R$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A transitive relation is irreflexive precisely when it is asymmetric. See page \pageref{org-special-block-extras-glossary-declaration-site-Transitive}

\vspace{1em}\phantomsection\textbf{Reflexive}\quad\label{org-special-block-extras-glossary-Reflexive}/Elements are related to themselves/ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}A relation $R : V → V$ can be visualised as a drawing: A dot for each element \newline{\color{white}.}$x$ of $V$, and a directed line $x ⟶ y$ between two points exactly when $x 〔R〕 \newline{\color{white}.}y$. \quad That is relations are /simple graphs/; one refers to the directed lines as \newline{\color{white}.}/edges/ and the dots as /nodes/. \newline{\color{white}.} \newline{\color{white}.}As a simple graph, reflexivity means /there is loop “ ⟳ ” at each node./ \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.} \quad  /R/ is reflexive exactly when /everything is related to itself/. \newline{\color{white}.}≡ \quad /∀ x • x 〔R〕 x/ \newline{\color{white}.}≡ \quad $Id ⊆ R$ \newline{\color{white}.} \newline{\color{white}.}Where /⨾, ⊤, ⊥, Id, ˘, ∼/ are relation composition, the universal relation, the \newline{\color{white}.}empty relation, the identity relation, relation converse (transpose), and complement. See page \pageref{org-special-block-extras-glossary-declaration-site-Reflexive}

\vspace{1em}\phantomsection\textbf{Commutative}\quad\label{org-special-block-extras-glossary-Commutative}An operation _⊕_ is /commutative/ or /symmetric/ if it satisfies /x ⊕ y = y ⊕ x/. \newline{\color{white}.} \newline{\color{white}.}This property indicates (semantically) that the value of an ⊕-expression doesn't \newline{\color{white}.}depend on the order of its arguments and (syntactically) we may swap their order \newline{\color{white}.}when manipulating ⊕-expressions. See page \pageref{org-special-block-extras-glossary-declaration-site-Commutative}

\vspace{1em}\phantomsection\textbf{Distributive}\quad\label{org-special-block-extras-glossary-Distributive}An operation ⊗ distributes over ⊕ when they satisfy \newline{\color{white}.}“left-distributivity” $x ⊗ (y ⊕ z) = (x ⊗ y) ⊕ (x ⊗ y)$ \newline{\color{white}.}and \newline{\color{white}.}“right-distributivity” $(y ⊕ z) ⊗ x = (y ⊗ x) ⊕ (z ⊗ x)$. \newline{\color{white}.} \newline{\color{white}.}When ⊕ = ⊗, one says that the operation is “self-distributive”. \newline{\color{white}.} \newline{\color{white}.}Distributivity can be viewed in two ways, much like distributivity of \newline{\color{white}.}multiplication × over addition +. Replacing the left side by the right side \newline{\color{white}.}could be called “multiplying out”; replacing the right side by the left side, \newline{\color{white}.}“factoring”. See page \pageref{org-special-block-extras-glossary-declaration-site-Distributive}

\vspace{1em}\phantomsection\textbf{Identity}\quad\label{org-special-block-extras-glossary-Identity}An operation _⊕_ has identity 𝑰 when it satisfies $𝑰 ⊕ x = x = x ⊕ 𝑰$. \newline{\color{white}.} \newline{\color{white}.}If it satisfies only the first equation, $𝑰 ⊕ x = x$, one says \newline{\color{white}.}that “𝑰 is a left-identity for ⊕”. If it satisfies only the second \newline{\color{white}.}equation, $x ⊕ 𝑰 = x$, one says that “𝑰 is a right-identity for ⊕”. \newline{\color{white}.} \newline{\color{white}.}For example, implication only has a left identity, $(false ⇒ x) = x$, and \newline{\color{white}.}subtraction only has a right identity, $(x - 0) = x$. \newline{\color{white}.} \newline{\color{white}.}An identity implies that occurrences of “⊕ 𝑰” and “𝑰 ⊕” in an expression are \newline{\color{white}.}redundant. Thus, $x ⊕ 𝑰$ may be replaced by $x$ in any expression without \newline{\color{white}.}changing the value of the expression. Therefore, we usually eliminate such \newline{\color{white}.}occurrences unless something encourages us to leave them in. See page \pageref{org-special-block-extras-glossary-declaration-site-Identity}

\vspace{1em}\phantomsection\textbf{Associative}\quad\label{org-special-block-extras-glossary-Associative}An operation _⊕_ is associative when it satisfies $(p ⊕ q) ⊕ r = p ⊕ (q ⊕ r)$. \newline{\color{white}.} \newline{\color{white}.}Associativity allows us to be informal and insert or delete pairs of \newline{\color{white}.}parentheses in sequences of ⊕'s, just as we do with sequences of \newline{\color{white}.}additions ---e.g., $a + b + c + d$ is equivalent to $a + (b + c) + d$. \newline{\color{white}.} \newline{\color{white}.}Hence, we can write $p ⊕ q ⊕ r$ instead of $(p ⊕ q) ⊕ r$ or $p ⊕ (q ⊕ r)$. \newline{\color{white}.} \newline{\color{white}.}When an operation is associative, it is best to avoid “making a choice” of how \newline{\color{white}.}sequences of ⊕ should be read, by using parentheses ---unless to make things \newline{\color{white}.}clear or explicit for manipulation. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}More generally, for any two operations _⊕_ and _⊞_, the “(left to right) mutual \newline{\color{white}.}associativity of ⊕ and ⊞” is the property $(x ⊕ y) ⊞ z = x ⊕ (y ⊞ z)$. It allows \newline{\color{white}.}us to omit parentheses in mixed sequences of ⊕ and ⊞. For instance, addition and \newline{\color{white}.}subtraction are (left to right) mutually associative. See page \pageref{org-special-block-extras-glossary-declaration-site-Associative}

\vspace{1em}\phantomsection\textbf{Category Theory}\quad\label{org-special-block-extras-glossary-cat}A theory of typed \quad composition; e.g., typed monoids. See page \pageref{org-special-block-extras-glossary-declaration-site-cat}

\vspace{1em}\phantomsection\textbf{Natural Transformation}\quad\label{org-special-block-extras-glossary-nat-trans}Natural transformations are essentially polymorphic functions that make /no/ \newline{\color{white}.} choices according to the input type; e.g., =reverse : List τ → List τ= makes no \newline{\color{white}.} choices depending on the type ~τ~. See page \pageref{org-special-block-extras-glossary-declaration-site-nat-trans}

\vspace{1em}\phantomsection\textbf{Algorithmic Problem Solving}\quad\label{org-special-block-extras-glossary-Algorithmic_Problem_Solving}There are two ways to read this phrase. \newline{\color{white}.} \newline{\color{white}.} Algorithmic-problem solving is about solving problems that \newline{\color{white}.} involve the construction of an algorithm for their solution. \newline{\color{white}.} \newline{\color{white}.} Algorithmic problem-solving is about problem solving in general, \newline{\color{white}.} using the principles of correct-by-construction algorithm-design. See page \pageref{org-special-block-extras-glossary-declaration-site-Algorithmic_Problem_Solving}

\vspace{1em}\phantomsection\textbf{Proving_is_Programming}\quad\label{org-special-block-extras-glossary-Proving_is_Programming}Problems may be formulated and solved using, possibly implicitly, the \newline{\color{white}.} construction of correct programs: \newline{\color{white}.} \newline{\color{white}.} \quad  \quad  /“for all x satisfying R(x), there is a y such that G(x,y) is true”/ \newline{\color{white}.} ≈	/∀ x • R x ⇒ ∃ y • G x y/ \newline{\color{white}.} ≈	/R {𝑺} G for some program 𝑺 with inputs x and outputs y/ \newline{\color{white}.} \newline{\color{white}.} This is known as a /constructive proof/ since we have an algorithm 𝑺 that actually \newline{\color{white}.} shows how to find a particular /y/ to solve the problem, for any given x. In \newline{\color{white}.} contrast, non-constructive proofs usually involving some form of counting \newline{\color{white}.} followed by a phrase “there is at least one such /y/ …”, without actually \newline{\color{white}.} indicating /how/ to find it! \newline{\color{white}.} \newline{\color{white}.} The /“R {𝑺} G”/ is known as a ‘Hoare triple’ and it expresses “when begun in a \newline{\color{white}.} state satisfying /R/, program 𝑺 will terminate in a state satisfying /G/.” \newline{\color{white}.} \newline{\color{white}.} -------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.} + Proving ≈ Programming \newline{\color{white}.} + Logic \quad  ≈ Trees (algebraic data types, 𝒲-types) \newline{\color{white}.} + Rules \quad  ≈ Constructors \newline{\color{white}.} + Proof \quad  ≈ An application of constructors \newline{\color{white}.} + Axiom \quad  ≈ A constructor with no arguments See page \pageref{org-special-block-extras-glossary-declaration-site-Proving_is_Programming}

\vspace{1em}\phantomsection\textbf{Specification}\quad\label{org-special-block-extras-glossary-Specification}A specification is an equation of a certain shape. \newline{\color{white}.} \quad /Programming/ is the activity of solving a specification \newline{\color{white}.} \quad for its unknown. Its unknown is called a /program/. \newline{\color{white}.} \newline{\color{white}.} \quad See also “Programming”. See page \pageref{org-special-block-extras-glossary-declaration-site-Specification}

\vspace{1em}\phantomsection\textbf{Programming}\quad\label{org-special-block-extras-glossary-Programming}Programming is solving the equation /R ⇒[C] G/ in the unknown /C/; i.e., it is the \newline{\color{white}.} activity of finding a ‘recipe’ that satisfies a given specification. Sometimes \newline{\color{white}.} we may write /R ⇒[?] G/ and solve for ‘?’. Programming is a goal-directed activity: From a specification, a program is found by examining the shape of its postcondition. See page \pageref{org-special-block-extras-glossary-declaration-site-Programming}

\vspace{1em}\phantomsection\textbf{Calculational Proof}\quad\label{org-special-block-extras-glossary-Calculational_Proof}A story whose events have smooth transitions connecting them. \newline{\color{white}.} \newline{\color{white}.}# A proof wherein each step is connected to the next step by an explicit \newline{\color{white}.}# justification. \newline{\color{white}.} \newline{\color{white}.}This is a ‘linear’ proof format; also known as /equational style/ or /calculational \newline{\color{white}.}proof/. This corresponds to the ‘high-school style’ of writing a sequence of \newline{\color{white}.}equations, one on each line, along with hints/explanations of how each line was \newline{\color{white}.}reached from the previous line. ( This is similar to *programming* which \newline{\color{white}.}encourages placing /comments/ to /communicate/ what's going on to future readers. ) \newline{\color{white}.} \newline{\color{white}.}The structure of equational proofs allows implicit use of infernece rules \newline{\color{white}.}Leibniz, Transitvitity \& Symmetry \& Reflexivity of equality, and \newline{\color{white}.}Substitution. In contrast, the structure of proof trees is no help in this \newline{\color{white}.}regard, and so all uses of inference rules must be mentioned explicitly. \newline{\color{white}.} \newline{\color{white}.}For comparison with other proof notations see [[http://www.cse.yorku.ca/~logicE/misc/logicE_intro.pdf][Equational Propositional Logic]]. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}We advocate /calculational proofs/ in which reasoning is goal directed and \newline{\color{white}.}justified by simple axiomatic laws that can be checked syntactically rather than \newline{\color{white}.}semantically. ---/Program Construction/ by Roland Backhouse \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Calculational proofs introduce notation and recall theorems as needed, thereby \newline{\color{white}.}making each step of the argument easy to verify and follow. Thus, such arguments \newline{\color{white}.}are more accessible to readers unfamiliar with the problem domain. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}The use of a formal approach let us keep track of when our statements are \newline{\color{white}.}equivalent (“=”) rather than being weakened (“⇒”). That is, the use of English \newline{\color{white}.}to express the connection between steps is usually presented naturally using “if \newline{\color{white}.}this, then that” statements ---i.e., implication--- rather than stronger notion \newline{\color{white}.}of equality. See page \pageref{org-special-block-extras-glossary-declaration-site-Calculational_Proof}

\vspace{1em}\phantomsection\textbf{Semantics}\quad\label{org-special-block-extras-glossary-Semantics}*Syntax* refers to the structure of expressions, or the rules for putting symbols \newline{\color{white}.}together to form an expression. *Semantics* refers to the meaning of expressions \newline{\color{white}.}or how they are evaluated. \newline{\color{white}.} \newline{\color{white}.}Abstractions express something shared by their instances, such as the kinds of \newline{\color{white}.}operations one can perform. However, abstractions don't, by themselves, “mean” \newline{\color{white}.}anything! E.g., for Haskell, the ~Monad~ type class does not mean anything, but \newline{\color{white}.}for the ~Maybe~ implementation it means short-circuit sequencing and for the ~List~ \newline{\color{white}.}implementation it means (possibly nested) iteration. \newline{\color{white}.}Abstractions for operations are also known as “design patterns”. \newline{\color{white}.}( With judicious use of Yoneda, things always denote/mean certain actions. ) \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}An expression can contain variables, and evaluating such an expression requires \newline{\color{white}.}knowing what values to use for these variables; i.e., a *state*: A list of \newline{\color{white}.}variables with associated values. E.g., evaluation of $x - y + 2$ in the state \newline{\color{white}.}consisting of $(x, 5)$ and $(y, 6)$ is performed by replacing $x$ and $y$ by \newline{\color{white}.}their values to yield $5 - 6 + 2$ and then evaluating that to yield $1$. \newline{\color{white}.} \newline{\color{white}.}A Boolean expression $P$ is *satisfied* in a state if its value is /true/ in that \newline{\color{white}.}state; $P$ is *satisfiable* if there is a state in which it is satisfied; and $P$ \newline{\color{white}.}is *valid* (or is a *tautology*) if it is satisfied in every state. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Often operations are defined by how they are evaluated (*operationally*), we can \newline{\color{white}.}take the alternative route of defining operations by how they can be manipulated \newline{\color{white}.}(*axiomatically*); i.e., by what properties they satisfy. \newline{\color{white}.} \newline{\color{white}.}For example, evaluation of the expression $X = Y$ in a state yields the value \newline{\color{white}.}/true/ if expressions $X$ and $Y$ have the same value and yields /false/ if they \newline{\color{white}.}have different values. \quad This characterisation of equality is in terms of \newline{\color{white}.}expression /evaluation/. \quad For /reasoning about expressions/, a more useful \newline{\color{white}.}characterisation would be a set of /laws/ that can be used to show that two \newline{\color{white}.}expressions are equal, *without* calculating their values. \newline{\color{white}.}--- c.f., static analysis versues running a program. \newline{\color{white}.} \newline{\color{white}.}For example, you know that $x = y$ equals $y = x$, regardless of the values of \newline{\color{white}.}$x$ and $y$. \quad A collection of such laws can be regarded as a definition of \newline{\color{white}.}equality, *provided* two expressions have the same value in all states precisely \newline{\color{white}.}when one expression can be translated into the other according to the laws. \newline{\color{white}.} \newline{\color{white}.}Usually, in /a/ logic, theorems correspond to expressions that are true in all \newline{\color{white}.}states. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}That is, instead of defining expressions by how they are evaluated, we may \newline{\color{white}.}define expressions in terms of how they can be manipulated ---c.f., a calculus. \newline{\color{white}.} \newline{\color{white}.}For instance, we may define basic manipulative properties of operators ---i.e., \newline{\color{white}.}/axioms/--- by considering how the operators behave operationally on particular \newline{\color{white}.}expressions. That is, one may use an operational, intuitive, approach to obtain \newline{\color{white}.}an axiomatic specification (characterisation, interface) of the desired \newline{\color{white}.}properties. \newline{\color{white}.} \newline{\color{white}.}More concretely, since $(p ≡ q) ≡ r$ and $p ≡ (q ≡ r)$ evaluate to \newline{\color{white}.}the same value for any choice of values for $p, q, r$, we may insist that a part \newline{\color{white}.}of the definition of equivalence is that it be an associative operation. \newline{\color{white}.} \newline{\color{white}.}Sometimes a single axiom is not enough to ‘pin down’ a unique operator ---i.e., \newline{\color{white}.}to ensure we actually have a well-defined operation--- and other times this is \newline{\color{white}.}cleanly possible; e.g., given an ordering ‘≤’(‘⇒, ⊆, ⊑’) we can define minima \newline{\color{white}.}‘↓’ (‘∧, ∩, ⊓’) by the axiom: “x ↓ y is the greatest lower bound”; \newline{\color{white}.}i.e., $z ≤ x ↓ y \quad≡\quad z ≤ x \,∧\, z ≤ y$. See page \pageref{org-special-block-extras-glossary-declaration-site-Semantics}

\vspace{1em}\phantomsection\textbf{Calculus}\quad\label{org-special-block-extras-glossary-Propositional_Calculus}A /calculus/ is a method or process of reasoning by calculation \newline{\color{white}.}with symbols. A /propositional calculus/ is a method of calculating with Boolean \newline{\color{white}.}(or propositional) expressions. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Calculus: Formalised reasoning through calculation. \newline{\color{white}.} \newline{\color{white}.}‘Hand wavy’ English arguments tend to favour case analysis —considering what \newline{\color{white}.}could happen in each possible scenario— which increases exponentially with each \newline{\color{white}.}variable; in contrast, equality-based calculation is much simpler since it \newline{\color{white}.}delegates intricate case analysis into codified algebraic laws. See page \pageref{org-special-block-extras-glossary-declaration-site-Propositional_Calculus}

\vspace{1em}\phantomsection\textbf{Calculus}\quad\label{org-special-block-extras-glossary-Calculus}A /calculus/ is a method or process of reasoning by calculation \newline{\color{white}.}with symbols. A /propositional calculus/ is a method of calculating with Boolean \newline{\color{white}.}(or propositional) expressions. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Calculus: Formalised reasoning through calculation. \newline{\color{white}.} \newline{\color{white}.}‘Hand wavy’ English arguments tend to favour case analysis —considering what \newline{\color{white}.}could happen in each possible scenario— which increases exponentially with each \newline{\color{white}.}variable; in contrast, equality-based calculation is much simpler since it \newline{\color{white}.}delegates intricate case analysis into codified algebraic laws. See page \pageref{org-special-block-extras-glossary-declaration-site-Calculus}

\vspace{1em}\phantomsection\textbf{Metatheorem}\quad\label{org-special-block-extras-glossary-Metatheorem}A /theorem/ in the technical sense is an expression derived \newline{\color{white}.}from axioms using inference rules. \newline{\color{white}.} \newline{\color{white}.}A /metatheorem/ is a general *statement* about a logic that \newline{\color{white}.}one argues to be *true*. \newline{\color{white}.} \newline{\color{white}.}For instance, “any two theorems are equivalent” is a statement that speaks about \newline{\color{white}.}expressions which happen to be theorems. A logic may not have the linguistic \newline{\color{white}.}capability to speak of its own expressions and so the statement may not be \newline{\color{white}.}expressible as an expression *within* the logic ---and so cannot be a theorem of \newline{\color{white}.}the logic. \newline{\color{white}.} \newline{\color{white}.}For instance, the logic 𝒑𝑞 has expressions formed from the symbols “𝒑”, “𝒒”, and \newline{\color{white}.}“-” (dash). It has the axiom schema $x𝒑-𝒒x-$ and the rule “If $x𝒑y𝒒z$ is a theorem \newline{\color{white}.}then so is $x-𝒑y-𝒒z-$”. Notice that $x, y, z$ are /any/ strings of dashes; \newline{\color{white}.}the language of this logic does not have variables and so cannot even speak \newline{\color{white}.}of its own expressions, let alone its own theorems! \newline{\color{white}.} \newline{\color{white}.}[Informal] theorems about [technical, logic-specific] theorems are thus termed \newline{\color{white}.}‘metatheorems’. See page \pageref{org-special-block-extras-glossary-declaration-site-Metatheorem}

\vspace{1em}\phantomsection\textbf{Theorem}\quad\label{org-special-block-extras-glossary-Theorem}A /theorem/ is a syntactic object, a string of symbols with a particular property. \newline{\color{white}.} \newline{\color{white}.}A /theorem/ of a calculus is either an axiom or the conclusion of an inference \newline{\color{white}.}rule whose premises are theorems. \newline{\color{white}.} \newline{\color{white}.}Different axioms could lead to the same set of theorems, and many texts use \newline{\color{white}.}different axioms. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A “theorem” is a syntactic concept: Can we play the game of moving symbols to \newline{\color{white}.}get this? Not “is the meaning of this true”! \quad ‘Semantic concepts’ rely on \newline{\color{white}.}‘states’, assignments of values to variables so that we can ‘evaluate, simplify’ \newline{\color{white}.}statements to deduce if they are true. \newline{\color{white}.} \newline{\color{white}.}Syntax is like static analysis; semantics is like actually running the program \newline{\color{white}.}(on some, or all possible inputs). \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A *meta-theorem* is a general statement about our logic that we prove to be \newline{\color{white}.}true. That is, if 𝑬 is collection of rules that allows us to find truths, then a \newline{\color{white}.}/theorem/ is a truth found using those rules; whereas a meta-theorem/ is property \newline{\color{white}.}of 𝑬 itself, such as what theorems it can have. \quad That is, theorems are _in_ 𝑬 and \newline{\color{white}.}meta-theorems are _about_ 𝑬. \quad For example, here is a meta-theorem that the \newline{\color{white}.}equational logic 𝑬 has (as do many other theories, such as lattices): An \newline{\color{white}.}/equational/ theorem is true precisely when its ‘dual’ is true. Such metatheorems \newline{\color{white}.}can be helpful to discover new theorems. \newline{\color{white}.} \newline{\color{white}.}# A meta-theorem is a theorem about theorems. See page \pageref{org-special-block-extras-glossary-declaration-site-Theorem}

\vspace{1em}\phantomsection\textbf{Logic}\quad\label{org-special-block-extras-glossary-Logic}A /logic/ is a formal system of reasoning... \newline{\color{white}.} \newline{\color{white}.}A /logic/ is a set of symbols along with a set of /formulas/ formed from the \newline{\color{white}.}symbols, and a set of /inference rules/ which allow formulas to be derived from \newline{\color{white}.}other formulas. (The formulas may or may not include a notion of variable.) \newline{\color{white}.} \newline{\color{white}.}Logics are purely syntactic objects; an /inference rule/ is a syntactic mechanism \newline{\color{white}.}for deriving “truths” or “theorems”. \newline{\color{white}.} \newline{\color{white}.}In general, proofs are evidence of truth of a claim; by demonstrating that the \newline{\color{white}.}claim follows from some /obvious truth/ using rules of reasoning that /obviously \newline{\color{white}.}preserve truth./ See page \pageref{org-special-block-extras-glossary-declaration-site-Logic}

\vspace{1em}\phantomsection\textbf{Inference_Rule}\quad\label{org-special-block-extras-glossary-Inference_Rule}Formally, a “proof” is obtained by applying a number of “rules” to known results \newline{\color{white}.}to obtain new results; a “theorem” is the conclusion of a “proof”. \quad An “axiom” \newline{\color{white}.}is a rule that does not need to be applied to any existing results: It's just a \newline{\color{white}.}known result. \newline{\color{white}.} \newline{\color{white}.}That is, a *rule* $R$ is a tuple $P₁, …, Pₙ, C$ that is thought of as ‘taking \newline{\color{white}.}*premises* (instances of known results) $Pᵢ$’ and acting as a ‘natural, \newline{\color{white}.}reasonable justification’ to obtain *conclusion* $C$. \quad A *proof system* is a \newline{\color{white}.}collection of rules. At first sight, this all sounds very abstract and rather \newline{\color{white}.}useless, however it is a /game/: *Starting from rules, what can you obtain?* Some \newline{\color{white}.}games can be very fun! Another way to see these ideas is from the view of \newline{\color{white}.}programming: \newline{\color{white}.} \newline{\color{white}.}+ Proving ≈ Programming \newline{\color{white}.}+ Logic \quad  ≈ Trees (algebraic data types, 𝒲-types) \newline{\color{white}.}+ Rules \quad  ≈ Constructors \newline{\color{white}.}+ Proof \quad  ≈ An application of constructors \newline{\color{white}.}+ Axiom \quad  ≈ A constructor with no arguments \newline{\color{white}.} \newline{\color{white}.}Just as in elementary school one sees addition ‘+’ as a fraction with the \newline{\color{white}.}arguments above the horizontal line and their sum below the line, so too is that \newline{\color{white}.}notation reused for inference rules: Premises are above the fraction's bar and \newline{\color{white}.}the conclusion is below. \newline{\color{white}.}#+begin_example \newline{\color{white}.} \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  12 \newline{\color{white}.}P₁, P₂, …, Pn \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad + \quad 7 \newline{\color{white}.}---------------R \quad  \quad  versues \quad  \quad  ---- \newline{\color{white}.} \quad  \quad  \quad C \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad  \quad 19 \newline{\color{white}.}#+end_example \newline{\color{white}.} \newline{\color{white}.}Just as there are meta-variables and meta-theorems, there is ‘meta-syntax’: \newline{\color{white}.}- The use of a fraction to delimit premises from conclusion is a form of ‘implication’. \newline{\color{white}.}- The use of a comma, or white space, to separate premises is a form of ‘conjunction’. \newline{\color{white}.} \newline{\color{white}.}If our expressions actually have an implication and conjunction operation, then \newline{\color{white}.}inference rule above can be presented as an axiom $P₁ \,∧\, ⋯ \,∧\, Pₙ \,⇒\, C$. \newline{\color{white}.} \newline{\color{white}.}The inference rule says “if the $Pᵢ$ are all valid, i.e., true in /all states/, \newline{\color{white}.}then so is $C$”; the axiom, on the other hand, says “if the $Pᵢ$ are true in /a \newline{\color{white}.}state/, then $C$ is true in /that state/.” Thus the rule and the axiom are not \newline{\color{white}.}quite the same. \newline{\color{white}.} \newline{\color{white}.}Moreover, the rule is not a Boolean expression. \quad Rules are thus more general, \newline{\color{white}.}allowing us to construct systems of reasoning that have no concrete notions of \newline{\color{white}.}‘truth’ ---e.g., the above arithmetic rule says from the things above the \newline{\color{white}.}fraction bar, using the operation ‘+’, we /can get/ the thing below the bar, but \newline{\color{white}.}that thing (19) is not ‘true’ as we may think of conventional truth. \newline{\color{white}.} \newline{\color{white}.}Finally, the rule asserts that $C$ follows from $P₁, …, Pₙ$. \quad The formula $P₁ \newline{\color{white}.}\,∧\, ⋯ \,∧\, Pₙ \,⇒\, C$, on the other hand, is an expression (but it need not \newline{\color{white}.}be a theorem). \newline{\color{white}.} \newline{\color{white}.}A “theorem” is a syntactic concept: Can we play the game of moving symbols to \newline{\color{white}.}get this? Not “is the meaning of this true”! \quad ‘Semantic concepts’ rely on \newline{\color{white}.}‘states’, assignments of values to variables so that we can ‘evaluate, simplify’ \newline{\color{white}.}statements to deduce if they are true. \newline{\color{white}.} \newline{\color{white}.}Syntax is like static analysis; semantics is like actually running the program \newline{\color{white}.}(on some, or all possible inputs). \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}One reads/writes a /natural deduction proof (tree)/ from the very *bottom*: Each \newline{\color{white}.}line is an application of a rule of reasoning, whose assumptions are above the \newline{\color{white}.}line; so read/written upward. \quad The *benefit* of this approach is that *rules guide \newline{\color{white}.}proof construction*; i.e., it is goal-directed. \newline{\color{white}.} \newline{\color{white}.}However the *downsides are numerous*: \newline{\color{white}.}- So much horizontal space is needed even for simple proofs. \newline{\color{white}.}- One has to *repeat* common subexpressions; e.g., when using transitivity of equality. \newline{\color{white}.}- For comparison with other proof notations, such as Hilbert style, \newline{\color{white}.} \quad see [[http://www.cse.yorku.ca/~logicE/misc/logicE_intro.pdf][Equational Propositional Logic]]. \newline{\color{white}.} \newline{\color{white}.} \quad This is more ‘linear’ proof format; also known as /equational style/ or \newline{\color{white}.} \quad /calculational proof/. This corresponds to the ‘high-school style’ of writing a \newline{\color{white}.} \quad sequence of equations, one on each line, along with hints/explanations of how \newline{\color{white}.} \quad each line was reached from the previous line. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Finally, an inference rule says that it is possible to start with the givens \newline{\color{white}.}$Pᵢ$ and obtain as result $C$. \quad The idea to use *inference rules as computation* \newline{\color{white}.}is witnessed by the [[https://alhassy.github.io/PrologCheatSheet/CheatSheet.pdf][Prolog]] programming language. See page \pageref{org-special-block-extras-glossary-declaration-site-Inference_Rule}

\vspace{1em}\phantomsection\textbf{Textual_Substitution}\quad\label{org-special-block-extras-glossary-Textual_Substitution}The *(simultaneous textual) Substitution operation* $E[\vec x ≔ \vec F]$ replaces \newline{\color{white}.}all variables $\vec x$ with parenthesised expressions $\vec F$ in an expression \newline{\color{white}.}$E$. In particular, $E[x ≔ F]$ is just $E$ but with all occurrences of $x$ \newline{\color{white}.}replaced by $“(F)”$. This is the “find-and-replace” utility you use on your \newline{\color{white}.}computers. \newline{\color{white}.} \newline{\color{white}.}Textual substitution on expressions is known as “grafting” on trees: Evaluate \newline{\color{white}.}$E[x ≔ F]$ by going down the tree $E$ and finding all the ‘leaves’ labelled $x$, \newline{\color{white}.}cut them out and replace them with the new trees $F$. \newline{\color{white}.} \newline{\color{white}.}Since expressions are either variables of functions applications, \newline{\color{white}.}substitution can be defined inductively/recursively by the following two clauses: \newline{\color{white}.} \newline{\color{white}.}+ /y[x ≔ F] \quad  \quad  \quad  \quad  \quad  \quad  = \quad if \quad x = y \quad then \quad F \quad else \quad y \quad fi/ \newline{\color{white}.}+ /f(t₁, …, tₙ)[x ≔ F] \quad = \quad f(t₁′, …, tₙ′) \quad  where \quad tᵢ′ = tᵢ[x ≔ F]/ \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Sequential ≠ Simultaneous: \newline{\color{white}.} \quad /(x + 2 · y)[x ≔ y][y ≔ x] \quad ≠ \quad (x + 2 · y)[x, y ≔ y, x]/ \newline{\color{white}.} \newline{\color{white}.}[[https://alhassy.github.io/PythonCheatSheet/CheatSheet.pdf][Python]], for example, has simultaneous /assignment/; \newline{\color{white}.}e.g., ~x, y = y, x~ is used to swap the value of two variables. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}A /function/ $f$ is a rule for computing a value from another value. \newline{\color{white}.} \newline{\color{white}.}If we define $f\, x = E$ using an expression, then /function application/ can be \newline{\color{white}.}defined using textual substitution: $f \, X = E[x ≔ X]$. That is, expressions \newline{\color{white}.}can be considered functions of their variables ---but it is still expressions \newline{\color{white}.}that are the primitive idea, the building blocks. See page \pageref{org-special-block-extras-glossary-declaration-site-Textual_Substitution}

\vspace{1em}\phantomsection\textbf{Induction}\quad\label{org-special-block-extras-glossary-Induction}How we prove a theorem $P\, n$ ranging over natural numbers $n$? \newline{\color{white}.} \newline{\color{white}.}For instance, suppose the property $P$ is that using only 3 and 5 dollar bills, \newline{\color{white}.}any amount of money that is at-least 8 dollars can be formed. \newline{\color{white}.} \newline{\color{white}.}Since there are an infinite number of natural numbers, it is not possibly to \newline{\color{white}.}verify $P\, n$ is true by /evaluating/ $P\, n$ at each natural number $n$. \newline{\color{white}.} \newline{\color{white}.}*Knocking over dominos is induction:* \newline{\color{white}.}The natural numbers are like an infinite number of dominoes ---i.e., standing \newline{\color{white}.}tiles one after the other, in any arrangement. Can all dominoes be knocked over? \newline{\color{white}.}That is, if we construe $P\, n$ to mean “the /n/-th domino can be knocked over”, \newline{\color{white}.}then the question is “is $∀ n • P\, n$ true”. Then, clearly if we can knock over \newline{\color{white}.}the first domino, $P\, 0$, and if when a domino is knocked over then it also \newline{\color{white}.}knocks over the next domino, $P\, n ⇒ P\, (n + 1)$, then ‘clearly’ all dominoes \newline{\color{white}.}will be knocked over. This ‘basic observation’ is known as /induction/. \newline{\color{white}.} \newline{\color{white}.}*Climbing a ladder is induction:* \newline{\color{white}.}The natural numbers are like an infinite ladder ascending to heaven. \quad Can we \newline{\color{white}.}reach every step, rung, on the ladder? \quad That is, if we construe $P\, n$ to mean \newline{\color{white}.}“the /n/-th rung is reachable”, then the question is “is $∀ n • P\, n$ \newline{\color{white}.}true”. Then, clearly if we can reach the first rung, $P\, 0$, and whenever we \newline{\color{white}.}climb to a rung then we can reach up and grab the next rung, $P\, n ⇒ P\, (n + \newline{\color{white}.}1)$, then ‘clearly’ all rungs of the ladder can be reached. This ‘basic \newline{\color{white}.}observation’ is known as /induction/. \newline{\color{white}.} \newline{\color{white}.}*Constant functions are induction:* \newline{\color{white}.}A predicate $P : ℕ → 𝔹$ is a function. When is such a function constantly the \newline{\color{white}.}value $\true$? That is, when is $∀ n • P\, n = \true$? \quad Clearly, if $P$ starts \newline{\color{white}.}off being $\true$ ---i.e., /P 0/--- and it preserves truth at every step ---i.e., \newline{\color{white}.}/P n ⇒ P (n + 1)/--- then /P n/ will be true for any choice of $n$. \newline{\color{white}.} \newline{\color{white}.}That is, if we consider $(ℕ, ≤)$ and $(𝔹, ⇒)$ as ordered sets and $P$ starts at \newline{\color{white}.}the ‘top’ of 𝔹 ---i.e., /P 0 = true/--- and it is ascending ---i.e., /P n ⇒ P (n + \newline{\color{white}.}1)/--- and so ‘never goes down’, then clearly it must stay constantly at the top \newline{\color{white}.}value of 𝔹. This ‘basic observation’ is known as /induction/. \newline{\color{white}.} \newline{\color{white}.} \newline{\color{white}.}⟦ For the money problem, we need to start somewhere else besides 0. ⟧ \newline{\color{white}.} \newline{\color{white}.}*Principle of (“Weak”) Mathematical Induction:* \newline{\color{white}.}To show that a property $P$ is true for all natural numbers starting with some \newline{\color{white}.}number $n_0$, show the following two properties: \newline{\color{white}.}+ Base case :: Show that $P\, n₀$ is true. \newline{\color{white}.}+ Inductive Step :: Show that whenever (the *inductive hypothesis*) $n$ is a \newline{\color{white}.} \quad natural number that such that $n ≥ n₀$ and $P\, n$ is true, then $P\, (n + 1)$ \newline{\color{white}.} \quad is also true. \newline{\color{white}.} \newline{\color{white}.}⟦ For the money problem, we need to be able to use the fact that to prove \newline{\color{white}.}$P\,(n + 1)$ we must have already proven $P$ for all smaller values. ⟧ \newline{\color{white}.} \newline{\color{white}.}*Principle of (“Strong”) Mathematical Induction*: \newline{\color{white}.}To show that a property $P$ is true for all natural numbers starting with some \newline{\color{white}.}number $n_0$, show the following two properties: \newline{\color{white}.}+ Base case :: Show that $P\, n₀$ is true. \newline{\color{white}.}+ Inductive Step :: Show that whenever (the *inductive hypothesis*) $n$ is a \newline{\color{white}.} \quad natural number that such that $n ≥ n₀$ and $P\, n_0, P\, (n_0 + 1), P\, (n_0 + \newline{\color{white}.} \quad 2), …, P\, n$ are true, then $P\, (n + 1)$ is also true. \newline{\color{white}.} \newline{\color{white}.}⟦ The ‘strength’ of these principles refers to the strength of the inductive \newline{\color{white}.}hypothesis. The principles are provably equivalent. ⟧ \newline{\color{white}.} \newline{\color{white}.}# (It is also a way to say that ℕ has non-empty meets.) \newline{\color{white}.}*The Least Number Principle (LNP) ---Another way to see induction:* \newline{\color{white}.}Every non-empty subset of the natural numbers must have a least element, \newline{\color{white}.}‘obviously’. This is (strong) induction. \newline{\color{white}.}# Possibly infinite! \newline{\color{white}.} \newline{\color{white}.}Application of LNP to showing that algorithms terminate: \newline{\color{white}.}In particular, every decreasing non-negative sequence of integers \newline{\color{white}.}$r₀ > r₁ > r₂ > ⋯$ must terminate. \newline{\color{white}.}#+end_box See page \pageref{org-special-block-extras-glossary-declaration-site-Induction}

\vspace{1em}\phantomsection\textbf{Expression}\quad\label{org-special-block-extras-glossary-Expression}An /expression/ is either a ‘variable’ or a ‘function application’; i.e., the name \newline{\color{white}.}of a function along with a number of existing expressions. \newline{\color{white}.} \newline{\color{white}.}#+begin_example \newline{\color{white}.} Expr ::= Constant \quad  \quad -- E.g., 1 or “apple” \newline{\color{white}.} \quad  \quad  \quad | \quad Variable \quad  \quad -- E.g., x or apple (no quotes!) \newline{\color{white}.} \quad  \quad  \quad | \quad Application -- E.g., f(x₁, x₂, …, xₙ) \newline{\color{white}.}#+end_example \newline{\color{white}.} \newline{\color{white}.}( One reads ‘:=’ as /becomes/ and so the addition of an extra colon results in a \newline{\color{white}.}‘stutter’: One reads ‘∷=’ as /be-becomes/. The symbol ‘|’ is read /or/. ) \newline{\color{white}.} \newline{\color{white}.}Notice that a constant is really just an application with /n/ being /0/ arguments \newline{\color{white}.}and so the first line in the definition above could be omitted. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}In a sense, an expression is like a sentence with the variables acting as \newline{\color{white}.}pronouns and the function applications acting as verb clauses and the argument \newline{\color{white}.}to the application are the participants in the action of the verbal clause. \newline{\color{white}.} \newline{\color{white}.}A *variable of type τ* is a /name/ denoting a yet unknown /value/ of type τ; \newline{\color{white}.}i.e., “it is a pronoun (nickname) referring to a person in the collection of people τ”. \newline{\color{white}.}E.g., to say $x$ is an integer variable means that we may treat it \newline{\color{white}.}as if it were a number whose precise value is unknown. \newline{\color{white}.}Then, if we let =Expr τ= refer to the expressions denoting /values/ of type τ; \newline{\color{white}.}then a *meta-variable* is simply a normal variable of type =Expr τ=. \newline{\color{white}.} \newline{\color{white}.}That is, when we write phrases like =“Let E be an expression”=, then the /name/ $E$ \newline{\color{white}.}varies and so is a variable, but it is an expression and so may consist of a \newline{\color{white}.}function application or a variable. *That is, $E$ is a variable that may stand \newline{\color{white}.}for variables.* This layered inception is resolved by referring to $E$ as not \newline{\color{white}.}just any normal variable, but instead as a *meta-variable*: A variable capable of \newline{\color{white}.}referring to other (simpler) variables. \newline{\color{white}.} \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} \newline{\color{white}.}Expressions, as defined above, are also known as /abstract syntax trees/ (AST) or \newline{\color{white}.}/prefix notation/. Then /textual substitution/ is known as ‘grafting trees’ (a \newline{\color{white}.}monadic bind). \newline{\color{white}.} \newline{\color{white}.}Their use can be clunky, such as by requiring many parentheses and implicitly \newline{\color{white}.}forcing a syntactic distinction between equivalent expressions; e.g., \newline{\color{white}.}/gcd(m,gcd(n,p))/ and /gcd(gcd(m,n),p)/ look difference even though /gcd/ is \newline{\color{white}.}associative. \newline{\color{white}.} \newline{\color{white}.}As such, one can declare /precedence levels/ ---a.k.a. /binding power/--- to reduce \newline{\color{white}.}parentheses, one can declare fixity ---i.e., have arguments around operation \newline{\color{white}.}names---, and, finally, one can declare association ---whether sequential \newline{\color{white}.}instances of an operation should be read with implicit parenthesis to the right \newline{\color{white}.}or the to the left--- to reduce syntactic differences. \quad The resulting expression \newline{\color{white}.}are now known to be in a /concrete syntax/ ---i.e., in a syntactic shape that is \newline{\color{white}.}more concrete. \newline{\color{white}.} \newline{\color{white}.}That is, the *conventions* on how a /string/ should be parsed as a /tree/ are known as a \newline{\color{white}.}*precedence, fixity, and associativity rules.* \newline{\color{white}.} \newline{\color{white}.}Similarly, not for operators but one treats /relations/ *conjunctionally* to reduce \newline{\color{white}.}the number of ‘and’(∧) symbols; e.g. $x ≤ y + 2 = z \quad≡\quad x ≤ (y + 2) \,∧\, (y + 2) = z$. \newline{\color{white}.}This is very useful to avoid repeating lengthy common expressions, such as /y + 2/. See page \pageref{org-special-block-extras-glossary-declaration-site-Expression}

\vspace{1em}\phantomsection\textbf{Graph}\quad\label{org-special-block-extras-glossary-graph}A /(Partial, resp. Total) Graph/ $G = (V, E, src, tgt)$ consists of \newline{\color{white}.} \quad  + $V$, a set of “points, nodes, vertices” \newline{\color{white}.} \quad  + $E$, a set of “arcs, edges” \newline{\color{white}.} \quad  + $src, tgt : E ↔ V$, a pair of /partial (resp. total)/ functions. \newline{\color{white}.} \newline{\color{white}.}⟦ Tersely put, in any category, a /graph/ is a parallel pair of morphisms. ⟧ \newline{\color{white}.} \newline{\color{white}.}/Edge parallelism/ is the relation $Ξ = src ⨾ src ˘ ∩ tgt ⨾ tgt˘$; two arcs are \newline{\color{white}.}related when they have the same starting point and the same ending point, which \newline{\color{white}.}both exist. Joyously, the name ‘Ξ’ is a neat reminder of the concept: \newline{\color{white}.}The name is three parallel lines, for the concept of edge(line) parallelism. \newline{\color{white}.} \newline{\color{white}.}+ A graph is /total/ exactly when /Id ⊆ Ξ/; and so Ξ is an equivalence. \newline{\color{white}.}+ A graph has /no parallel arrows/ exactly when /Ξ ⊆ Id/. \newline{\color{white}.}+ A graph is /simple/ exactly when /Ξ = Id/. \newline{\color{white}.} \newline{\color{white}.}The /associated relation/ is the relation /_⟶_ = src ˘ ⨾ tgt/ that relates two nodes \newline{\color{white}.}when the first is the source of some edge that happens to have the second point \newline{\color{white}.}as its target. One uses the associated relation to study properties not \newline{\color{white}.}involving partial or parallel arrows. One writes /⟵/ for /⟶˘/; \newline{\color{white}.}one writes ⟶⋆ for the /reachability/ relation. \newline{\color{white}.} \newline{\color{white}.}+ Node /y/ is /reachable via a non-empty path/ from node /x/ exactly when /x ⟶⁺ y/. \newline{\color{white}.} \quad - Node /x/ lies on a cycle exactly when /x ⟶⁺ x/. \newline{\color{white}.} \quad - A graph is /DAG, acylic, circuit-free,/ exactly when /⟶⁺ ⊆ ∼Id/; i.e., /⟶⁺ ∩ Id = ⊥/. \newline{\color{white}.} \quad - An acyclic graph is a (/directed) forest/ exactly when ⟶ is injective; i.e., \newline{\color{white}.} \quad  \quad every node has at most one predecessor; i.e., $⟶ ⨾ ⟵ ⊆ Id$. \newline{\color{white}.}+ A node /r/ is a /root/ exactly when every node is reachable from it; i.e., /{r} × V ⊆ ⟶⋆;/ \newline{\color{white}.} \quad i.e., /𝕃 r ⨾ ⟶⋆ = ⊤/ where /𝕃 r/ is defined by $𝕃 r = (ℝ r)˘$ and $x 〔ℝ r〕 y \;≡\; x = r$. \newline{\color{white}.} \quad - $x〔𝕃 r ⨾ R〕 y \;≡\; r〔R〕 y$ and $x 〔R ⨾ ℝ r〕 y \;≡\; x 〔R〕 r$ \newline{\color{white}.} \quad - A /tree/ is a forest with a root. \newline{\color{white}.}+ A graph is /loop free/ exactly when /⟶ ⊆ ∼Id/. \newline{\color{white}.}+ A graph is /strongly connected/ exactly when /⟶⋆ = ⊤/; i.e., /∼Id ⊆ ⟶⁺/; \newline{\color{white}.} \quad i.e., every point is reachable from any /other/ point; i.e., /∼Id ⊆ ⟶ ∩ ⟵˘/; \newline{\color{white}.} \quad i.e., any two distinct points lie on an undirected circuit. \newline{\color{white}.} \quad - The equivalence classes of /⟶⋆ ∩ ⟵⋆/ are the /strongly connected components/. \newline{\color{white}.}+ /Terminal∣sinks/ are nodes from which it is /not/ possible to proceed /any/ further; \newline{\color{white}.} \quad i.e., terminals have no successors; the domain of /∼(⟶ ⨾ ⊤)/ is all terminals. \newline{\color{white}.}+ /Initial∣sources/ are nodes from which it is /not/ possible to proceed backward; \newline{\color{white}.} \quad i.e., initials have no predecessors; the domain of /∼(⟵ ⨾ ⊤)/ is all initials. See page \pageref{org-special-block-extras-glossary-declaration-site-graph}

\vspace{1em}\phantomsection\textbf{Hello}\quad\label{org-special-block-extras-glossary-Hello}Language (Native Name) “Hello” \newline{\color{white}.}1. Amharic (አማርኛ)	ሠላም \newline{\color{white}.}2. Arabic (العربيّة)	السّلام عليكم \newline{\color{white}.}3. Armenian (հայերեն)	Բարև ձեզ \newline{\color{white}.}4. Bengali (বাংলা)	নমস্কার \newline{\color{white}.}5. Braille	⠓⠑⠇⠇⠕ \newline{\color{white}.}6. Burmese (မြန်မာ)	မင်္ဂလာပါ \newline{\color{white}.}7. C	printf ("Hello, world!\n"); \newline{\color{white}.}8. Cherokee (ᏣᎳᎩ ᎦᏬᏂᎯᏍᏗ)	ᎣᏏᏲ ╱ ᏏᏲ \newline{\color{white}.}9. Comanche ╱kəˈmæntʃiː╱	Haa marʉ́awe \newline{\color{white}.}10. Cree (ᓀᐦᐃᔭᐍᐏᐣ)	ᑕᓂᓯ ╱ ᐙᒋᔮ \newline{\color{white}.}11. Czech (čeština)	Dobrý den \newline{\color{white}.}12. Danish (dansk)	Hej ╱ Goddag ╱ Halløj \newline{\color{white}.}13. Dutch (Nederlands)	Hallo ╱ Dag \newline{\color{white}.}14. Efik \quad ╱ˈɛfɪk╱	Mɔkɔm \newline{\color{white}.}15. Emacs	emacs --no-splash -f view-hello-file \newline{\color{white}.}16. Emoji	👋 \newline{\color{white}.}17. English ╱ˈɪŋɡlɪʃ╱	Hello \newline{\color{white}.}18. Esperanto	Saluton (Eĥoŝanĝo ĉiuĵaŭde) \newline{\color{white}.}19. Estonian (eesti keel)	Tere päevast ╱ Tere õhtust \newline{\color{white}.}20. Finnish (suomi)	Hei ╱ Hyvää päivää \newline{\color{white}.}21. French (français)	Bonjour ╱ Salut \newline{\color{white}.}22. Georgian (ქართული)	გამარჯობა \newline{\color{white}.}23. German (Deutsch)	Guten Tag ╱ Grüß Gott \newline{\color{white}.}24. Greek (ελληνικά)	Γειά σας \newline{\color{white}.}25. Greek, ancient (ἑλληνική)	Οὖλέ τε καὶ μέγα χαῖρε \newline{\color{white}.}26. Gujarati (ગુજરાતી)	નમસ્તે \newline{\color{white}.}27. Hebrew (עִבְרִית)	שָׁלוֹם \newline{\color{white}.}28. Hungarian (magyar)	Szép jó napot! \newline{\color{white}.}29. Hindi (हिंदी)	नमस्ते ╱ नमस्कार । \newline{\color{white}.}30. Inuktitut (ᐃᓄᒃᑎᑐᑦ)	ᐊᐃ \newline{\color{white}.}31. Italian (italiano)	Ciao ╱ Buon giorno \newline{\color{white}.}32. Javanese (Jawa)	System.out.println("Sugeng siang!"); \newline{\color{white}.}33. Kannada (ಕನ್ನಡ)	ನಮಸ್ಕಾರ \newline{\color{white}.}34. Khmer (ភាសាខ្មែរ)	ជំរាបសួរ \newline{\color{white}.}35. Lao (ພາສາລາວ)	ສະບາຍດີ ╱ ຂໍໃຫ້ໂຊກດີ \newline{\color{white}.}36. Malayalam (മലയാളം)	നമസ്കാരം \newline{\color{white}.}37. Maldivian (ދިވެހި)	އައްސަލާމު ޢަލައިކުމް ╱ ކިހިނެހް؟ \newline{\color{white}.}38. Maltese (il-Malti)	Bonġu ╱ Saħħa \newline{\color{white}.}39. Mathematics	∀ p ∈ world • hello p \quad □ \newline{\color{white}.}40. Mongolian (монгол хэл)	Сайн байна уу? \newline{\color{white}.}41. Norwegian (norsk)	Hei ╱ God dag \newline{\color{white}.}42. Oriya (ଓଡ଼ିଆ)	ଶୁଣିବେ \newline{\color{white}.}43. Polish \quad (język polski)	Dzień dobry! ╱ Cześć! \newline{\color{white}.}44. Russian (русский)	Здра́вствуйте! \newline{\color{white}.}45. Sinhala (සිංහල)	ආයුබෝවන් \newline{\color{white}.}46. Slovak (slovenčina)	Dobrý deň \newline{\color{white}.}47. Slovenian (slovenščina)	Pozdravljeni! \newline{\color{white}.}48. Spanish (español)	¡Hola! \newline{\color{white}.}49. Swedish (svenska)	Hej ╱ Goddag ╱ Hallå \newline{\color{white}.}50. Tamil (தமிழ்)	வணக்கம் \newline{\color{white}.}51. Telugu (తెలుగు)	నమస్కారం \newline{\color{white}.}52. TaiViet (ꪁꪫꪱꪣ ꪼꪕ)	ꪅꪰꪙꫂ ꪨꪮꫂ ꪁꪫꪱ ╱ ꪅꪽ ꪨꪷ ꪁꪫꪱ \newline{\color{white}.}53. Thai (ภาษาไทย)	สวัสดีครับ ╱ สวัสดีค่ะ \newline{\color{white}.}54. Tibetan (བོད་སྐད་)	བཀྲ་ཤིས་བདེ་ལེགས༎ \newline{\color{white}.}55. Tigrigna (ትግርኛ)	ሰላማት \newline{\color{white}.}56. Turkish (Türkçe)	Merhaba \newline{\color{white}.}57. Ukrainian (українська)	Вітаю \newline{\color{white}.}58. Vietnamese (tiếng Việt)	Chào bạn \newline{\color{white}.}59. Japanese (日本語)	こんにちは ╱ ｺﾝﾆﾁﾊ \newline{\color{white}.}60. Chinese (中文,普通话,汉语)	你好 \newline{\color{white}.}61. Cantonese (粵語,廣東話)	早晨, 你好 \newline{\color{white}.}62. Korean (한글)	안녕하세요 ╱ 안녕하십니까 \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.}This list was generated by pressing ~C-h h~ in Emacs, ~view-hello-file~. See page \pageref{org-special-block-extras-glossary-declaration-site-Hello}

\vspace{1em}\phantomsection\textbf{Hussain}\quad\label{org-special-block-extras-glossary-Hussain}Hussein ibn Ali is the grandson of Prophet Muhammad, who is known to have \newline{\color{white}.}declared *“Hussain is from me and I am from Hussain; God loves whoever loves Hussain.”* \newline{\color{white}.} \newline{\color{white}.}He is honoured as “The Chief of Martyrs” for his selfless stand for social justice \newline{\color{white}.}against Yazid, the corrupt 7ᵗʰ caliph. The Karbala Massacre is commemorated annually \newline{\color{white}.}in the first Islamic month, Muharram, as a reminder to stand against oppression and tyranny; \newline{\color{white}.}Jesus Christ, son of Mary, makes an indirect appearance in the story. \newline{\color{white}.} \newline{\color{white}.}A terse summary of the chain of events leading to the massacre may be found at \newline{\color{white}.}https://www.al-islam.org/articles/karbala-chain-events. \newline{\color{white}.} \newline{\color{white}.}An elegant English recitation recounting the Karbala Massacre may be found at \newline{\color{white}.}https://youtu.be/2i9Y3Km6h08 ---“Arbaeen Maqtal - Sheikh Hamam Nassereddine - 1439”. \newline{\color{white}.}-------------------------------------------------------------------------------- \newline{\color{white}.} *Charles Dickens:* /“If Hussain had fought to quench his worldly desires...then I/ \newline{\color{white}.}/do not understand why his sister, wife, and children accompanied him. It stands \newline{\color{white}.}to reason therefore, that he sacrificed purely for Islam.”/ \newline{\color{white}.} \newline{\color{white}.}*Gandhi:* /“I learned from Hussain how to achieve victory while being oppressed.”/ \newline{\color{white}.} \newline{\color{white}.}*Thomas Carlyle:* /“The victory of Hussein, despite his minority, marvels me.”/ \newline{\color{white}.} \newline{\color{white}.}*Thomas Masaryk:* /“Although our clergies also move us while describing the \newline{\color{white}.}Christ's sufferings, but the zeal and zest that is found in the followers of/ \newline{\color{white}.}/Hussain will not be found in the followers of Christ. And it seems that the \newline{\color{white}.}suffering of Christ against the suffering of Hussain is like a blade of straw/ /in \newline{\color{white}.}front of a huge mountain.”/ See page \pageref{org-special-block-extras-glossary-declaration-site-Hussain}

\vspace{1em}\phantomsection\textbf{temp}\quad\label{org-special-block-extras-glossary-temp} See page \pageref{org-special-block-extras-glossary-declaration-site-temp}



 coffee|gray|\url{https://www.buymeacoffee.com/alhassy|buy-me-a-coffee}
\end{document}
